<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.41-DEV" />

  <title>miracle of light</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="http://wonder.zxcsoft.com/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="http://wonder.zxcsoft.com/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="http://wonder.zxcsoft.com/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  
  <link rel="alternate" type="application/rss+xml" title="miracle of light" href="http://wonder.zxcsoft.com/index.xml" />
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="http://wonder.zxcsoft.com/img/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="http://wonder.zxcsoft.com/">miracle</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://wonder.zxcsoft.com/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://wonder.zxcsoft.com/post/"><i class='fa fa-list fa-fw'></i>Posts</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://wonder.zxcsoft.com/tags/"><i class='fa fa-user fa-fw'></i>Tags</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="http://wonder.zxcsoft.com/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="http://wonder.zxcsoft.com/index.xml"><i class="fa fa-rss fa-fw"></i>RSS</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>&copy; 2016. All rights reserved.</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>miracle of light</h1>
  <h2>It&#39;s a dream and also a miracle!</h2>
</div>

<div class="content">
  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/linux/keepalived/keeplived/">keepalived心跳检测</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-11-05</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/linux">linux</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/keepalived">keepalived</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  keepalived 心跳检测 keepalived版本：1.4.5
流程说明  keepalived启动后，会fork出两个子进程：一个用于心跳检测，一个用于vrrp主结点选取（本文暂不细说） 心跳检测功能说明：读取keepalive.conf配置，解析vs（virtual server）rs(real server)，检测rs服务是否正常（创建sockert连接：只创建连接，连接成功就表示服务正常，不发心跳），服务正常，则配置ipvs
 keepalived任务调度说明（keepalived的心跳检测是单线程串行处理的）：
 keepalive心跳检测程序有这几个任务队列：event,child,ready,read,write,timer。队列的优先级从左到右从高到低（因为是串行处理，最先调度的优先级最高）。 心跳检测过程，只会涉及到timer,write,ready队列。 所有的任务都是由主线程来调度的，调度方法为：  如果event中有任务，则直接从event中取出执行 如果child中有任务，则直接从child中取出执行 如果ready中有任务，则直接从ready中取出执行 这里有一个至多1秒的休眠等待（遍历所有队列，取出离当前时间最近的任务的时间，和当前时间做差，如果大于1秒，则休眠1秒，如果小于，则按该时间休眠） 如果read中有任务，并且当中的socket fd可读，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中）。如果当前任务的调度时间大于当前时间，则将任务设置为超时，放入ready队列中 如果write中有任务，并且当中的socket fd可写，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中）。如果当前任务的调度时间大于当前时间，则将任务设置为超时，放入ready队列中 如果timer中有任务，并且调度时间大于或等于当前时间，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中） 取出ready中第一个任务并执行，没有取到任务则返回到第一步继续执行。   单组心跳检测流程（配置文件加载完，一组心跳检测就会生成一个任务A放入timer队列中）：
 一次心跳检测，会有两个任务
 任务A：创建socket连接。根据等到的fd创建任务B放到writer队列中。 任务B：读取socket fd连接状态，根据检测结果配置ipvs。创建一个新的任务A，放入timer队列中。 一组心跳检测就相当于检测一只鸡生蛋的过程。读取完配置文件，发现有100组心跳检测，就好比有100只要检测的鸡（任务A），这个时候都放在鸡窝（timer队列）中，每只鸡上都挂了个时间：生蛋的时间（调度时间），时间到了才调度。详细说明一只鸡（一组心跳检测）的处理流程：  调度者扫描timer队列（当然还有其它队列），发现鸡上的时间到了，把鸡取出来，放到产房（ready队列）中（因为有可能有多个满足条件的，所以一次都放到ready队列中） 调度者从ready队列中取出任务（当前是任务A），执行： 它完成下蛋，把蛋+检测方案（任务B）放到质检房（writer队列）中，同时写上超时时间（鸡蛋坏掉的时间）。 调度者扫描writer队列，发现有蛋了，将它放到ready队列中（任务B）（所有满足条件的），同时检查超时时间，如果时间已经过了（鸡蛋坏了），则修改任务状态为超时。 调度者从ready队列中取出任务（当前是任务B），执行： 先检查任务是不是超时，如果超时了，则直接认定检查失败。否则根据方案检测蛋，如果通过就更新该条ipvs，不通过就删除该条ipvs。然后再把鸡放回去（生成任务A&rsquo;），写下下一次下蛋时间（调度时间），放到timer队列中   ipvs配置示例：
  TCP 10.10.88.98:3306 wlc persistent 1800 -&gt; 10.244.1.222:3306 Masq 1 0 0 TCP 10.10.88.98:9104 wlc persistent 1800 -&gt; 10.244.1.222:9104 Masq 1 0 0  问题说明 程序配置更新了(配置文件中vs-rs的配置更新了)，keepalived也有不停的在更新配置文件的日志（keepalived已经收到信号重新加载了配置文件），但ipvs并没有生效（手工检查rs服务是正常的，但并没有vs-rs的ipvs配置）
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/linux/keepalived/keeplived/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/language/go/go-src/">go源码学习</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-26</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/golang">golang</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  启动过程  初始化参数 设置argc，argv 初始化系统 设置maxproc 初始化调度器
 初始化栈分配器stack 初始化内存分配器malloc 公共初始化
 处理命令行参数、环境变量：gorags，goenvs
 垃圾回收初始化gcinit
  runtime.main
 初始化runtime包中的所有init函数 启动垃圾回收 执行所有用户包中的init 进入main.main，用户逻辑入口   内存分配  go内存空间结构
 页所属 spans 512MB | gc标记位图 bitmap 32GB | 用户内存分配 arena 512GB （后面的空间为可能的最大空间）  分配器将内存为两种：span内存块，object内存对象
 使用tcmalloc来管理内存
 cache 每个线程都会绑定一个cache，用于无锁object分配 central 为所有cache提供切分好的后备span heap 管理闲置的span，需要时向系统申请新内存
 优先使用cache来分配对象，如果不足，再从central中优先找现有的span检查是否有可用空间，再不足，才到heap中申请span
  内存分配
 golang编译器支持逃逸分析(escape analysis)，编译期通过构建调用图来分析局部变量是否会被外部引用，从而决定是否可直接分配在栈上 编译参数 -gcflags &ldquo;-m&rdquo; 可输出编译优化信息  内存回收
 以span为单元，检查span内的object是否全部释放，将原本就为空的span转移到central.nonempty，将收回的span交还给heap。同时会尝试合并相邻的空的span  内存释放
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/language/go/go-src/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/kuber/kuber_docs/">kbuernetes docs 学习</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-23</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/kubernetes">kubernetes</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  kubernetes docs 学习  参考 http://docs.kubernetes.org.cn/251.html 对应源地址 https://kubernetes.feisky.xyz/zh/  kubernetes架构  etcd 保存整个集群的状态 apiserver 提供资源操作的唯一入口，并提供认证、授权、访问控制、api注册和发现等机制 controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler负责资源的调度，按照预定的调度策略将pod调度到相应的机器上 kubelet 负责维护容器的生命周期，同时也负责volume（cvi）和网络（cni）的管理 container runtime负责镜像管理以及pod和容器的真正运行（cri） kube-proxy 负责为service提供cluster内部的服务发现和负载均衡  除了这些核心组件，还有些扩展的add-ons： * kube-dns负责为整个集群提供dns服务 * ingress controller为服务提供外网入口 * heapster提供资源监控 * dashboard提供gui * fedreation提供跨可用区的集群 * fluentd-elasticsearch提供集群日志采集、存储与查询
kuber分层架构  核心层：kubernetes最核心的功能，对外提供api构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、dns解析等） 管理层：系统度量（如基础设置、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC，quota，psp，networkpolicy等） 接口层：kubectl命令行工具、客户端sdk以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分两个  kubernetes外部：日志、监控、配置管理、ci,cd,workflow,faas,ots应用,chatops kubernetes内部：cri,cni,cvi,镜像仓库，cloud provider,集群自身的配置和管理等   kubernetse的设计理念 api设计原则  所有api应该是声明式的（比如设置副本数为3，运行多次也没问题，而给副本数加1，运行多次就不对了） api对象是彼此互补而且可以组合的 高层api以操作意图为基础设计（从业务出发，而不是过早的从技术实现出发） 低层api根据高层api的控制需要设计（以需求为基础，尽量抵抗受技术实现影响的诱惑） 尽量避免简单封装，不要有在外部api无法显式知道的内部隐藏的机制（简单的封装实际没有提供新功能，反而增加对所封装api的依赖性。内部隐藏的机制不利于系统维护的设计方式） api操作复杂试与对象数量成正比 api对象状态不能依赖于网络连接状态（对象状态能应对网络不稳定） 尽量避免让操作机制依赖于全局状态，因为在分布式系统中要保证全局状态的同步是非常困难  控制机制设计原则  控制逻辑应该只依赖于当前状态 假设任何错误的可能，并做差错处理 尽量避免复杂状态机，控制逻辑不要依赖无法监控的内部状态 假设任何操作都可能被任何操作对象拒绝，甚至被错误解析（保证出现错误的时候，操作级别的错误不会影响到系统稳定性） 每个模块都可以在出错后自动恢复 每个模块都可以在必要时优雅的降级服务（划分清楚基本功能和高级功能，保证基本功能不会依赖高级功能，这样就保证了不会因为高级功能出现故障而导致整个模块崩溃）  kuber api对象  pod pod内的容器共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。比如，一个nginx容器用来发布软件，另一个容器专门用来从源仓库做同步 pod是所有业务类型的基础，k8s中业务主要分四类：  Deployment：长期伺服型（long-runing） Job：批处理型（batch） DaemonSet：节点后台支撑型（node-daemon） PetSet：有状态应用型（stateful application）    pod特征：  共享ipc、network、utc namespace的容器 所有pod内容器都可以访问共享的Volume，可以访问共享数据 pod一旦调度后就和node绑定，即使node挂掉也不会重新调度，推荐使用deployments、daemonsets等控制器来容错 优雅终止：pod删除的时候，先给其内的进程发送sigterm，等待一段时间（graceperiod）后才强制停止依然还在运行的进程 特权容器（通过SecurityContext配置）具有改变系统配置的权限（在网络插件中大量应用）    复制控制器（Replication Controller，RC） RC是k8s集群中最早的保证pod高可用的api对象，监控运行中的pod来保证集群中运行指定数目的pod副本。只适用于长期伺服型的业务类型
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/kuber/kuber_docs/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/oracle/oracle_lock/">oracle锁表问题</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-21</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/oracle">oracle</a>
    
  </div>
  
  

</div>

  </header>

  <p>
   查询oralce锁表 --查询锁表会话 SELECT s.username, decode(l.type,'TM','TABLE LOCK', 'TX','ROW LOCK', NULL) LOCK_LEVEL, o.owner,o.object_name,o.object_type, s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser FROM v$session s,v$lock l,dba_objects o WHERE l.sid = s.sid AND l.id1 = o.object_id(+) AND s.username is NOT Null --杀死事务 alter system kill session'SID,SERIAL#'; --查询锁表的sql语句 SELECT l.session_id sid, s.serial#, l.locked_mode, l.oracle_username, s.user#, l.os_user_name,s.machine, s.terminal,a.sql_text, a.action FROM v$sqlarea a,v$session s, v$locked_object l WHERE l.session_id = s.sid AND s.prev_sql_addr = a.address ORDER BY sid, s.serial#;  
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/web/dart/">dart use</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-12</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/dart">dart</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/js">js</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/d3">d3</a>
    
  </div>
  
  

</div>

  </header>

  <p>
   dart use d3.js import 'dart:html'; import 'package:js/js.dart' as js; void main() { var dee3 = js.context.d3; var dataset = js.array([ 5, 10, 15, 20, 25 ]); dee3.select(&quot;body&quot;).selectAll(&quot;p&quot;) .data(dataset) .enter() .append(&quot;p&quot;) .text((d, i, context) =&gt; d); }  
  </p>

  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/kuber/fluentd/">fluentd使用说明</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-05</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/kubernetes">kubernetes</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/fluentd">fluentd</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/td-agent">td-agent</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  fluentd配置说明  参考：https://docs.fluentd.org/v1.0/articles/filter-plugin-overview  filter配置说明  filter根据tag来匹配，可有多个filter对应同一个tag，处理按配置的顺序依次处理  筛选消息中包括cool的
&lt;filter foo.bar&gt; @type grep regexp1 message cool &lt;/filter&gt;  目前自带的filter有4个  filter_record_transformer 报文转换  语法格式：
&lt;record&gt; NEW_FIELD NEW_VALUE &lt;/record&gt;  tag的处理方法：
//tag_parts[N] 表示tag的第N个部分 tag_prefix[0] = debug tag_suffix[0] = debug.my.app tag_prefix[1] = debug.my tag_suffix[1] = my.app tag_prefix[2] = debug.my.app tag_suffix[2] = app  &lt;filter foo.bar&gt; @type record_transformer &lt;record&gt; hostname &quot;#{Socket.gethostname}&quot; #给报文增加两个域：hostname，tag tag ${tag} avg ${record[&quot;total&quot;] / record[&quot;count&quot;]} ##增加一个avg域，计算报文中total和count的除数 message yay, ${record[&quot;message&quot;]} ## 给message域增加个前缀 &lt;/record&gt; &lt;/filter&gt;   filter_grep 报文筛选  &lt;filter foo.
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/kuber/fluentd/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/kuber/kuber-logs/">kuber log analysis</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-05</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/kubernetes">kubernetes</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/fluentd">fluentd</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  kubernetes日志管理 参考资料：https://logz.io/blog/kubernetes-log-analysis/
1. 安装fluentd  参考官方文档：https://docs.fluentd.org/v1.0/articles/install-by-rpm#redhat-/-centos
 td-agent是对fluentd的封装，并加入了管理工具，比如java有集成的应用包
  curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent3.sh | sh #启动td-agent systemctl start td-agent #安装td-agent es插件 sudo /usr/sbin/td-agent-gem install fluent-plugin-elasticsearch --no-document  2. 配置说明  配置td-agent： 备份 /etc/td-agent/td-agent.conf  ## 增加一个测试的日志输入，用于测试解析日志并写入es &lt;source&gt; @type http @id input_http port 42185 tag http.test &lt;/source&gt; # 配置将收到的日志输入到控制台 &lt;match **&gt; @type stdout @id output_stdout &lt;/match&gt; # 配置将日志写入es &lt;match http.test&gt; #一个source的tag只会匹配一个match，有多个时，不会都匹配 @type elasticsearch logstash_format true host localhost port 9200 #hosts host1:port1,host2:port2,host3:port3 # or #hosts https://customhost.
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/kuber/kuber-logs/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/tools/rss_tools/">rss tools</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-04</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/rss">rss</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  rss 开源服务搭建，基于kuber+coredns+traefik 1.下载镜像 docker pull miniflux/miniflux:2.0.10 docker pull postgres:11-alpine  2.部署pg 1. 创建本地存储 apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-1 labels: type: local spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce hostPath: path: /data/pv/1  2. 创建存储使用申明  pvc到pv的绑定是，自动完成的，并且绑定后就是一对一的绑定，不会再改变。绑定考虑的是空间大小，如果没有合适的，会挂起，直到有合适的存储。kubectl get pvc 能看到具体的绑定情况 pvc的大小可以比pv小，用来实现存储大小的控制  apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pg-pv-claim labels: app: postgres spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi  3. 创建应用 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: pg-11 spec: replicas: 1 template: metadata: labels: app: pg-11 spec: containers: - name: pg image: postgres:11-alpine imagePullPolicy: IfNotPresent ports: - containerPort: 5432 env: - name: POSTGRES_PASSWORD value: wonder # 虽然pgdata目录没变，但要设置，目的是为了触发initdb调用 name: PGDATA value: /var/lib/postgresql/data/pgdata volumeMounts: - name: pg-pv-storage mountPath: /var/lib/postgresql/data/pgdata volumes: - name: pg-pv-storage persistentVolumeClaim: claimName: pg-pv-claim  4.
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/tools/rss_tools/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/kuber/docker-src/">docker源码分析</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-08-01</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/docker">docker</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  docker源码分析 读《docker源码分析》整理
容器说明  先有进程，后有容器 父进程通过fork创建子进程时，使用namespaces技术（CLONE_NEWNS,CLONE_NEWUTS,CLONE_NEWIPC,CLONE_PID,CLONE_NEWNET），实现子进程和父进程以及其它进程之间的命名空间的隔离 子进程创建完毕后，使用cgroups技术来处理进程，实现进程资源限制 这样，进程所处的“隔离”环境才真正建立，此时容器真正诞生  docker架构  docker有如下模块：
 DockerClient 发起容器管理请求，请求最终发往DockerDaemon DockerDaemon  接收请求，所有的任务由engine来完成，每一项工作都以job形式存在 管理所有的容器 大致分为三部分：  docker server 它本身是一个名为serveapi的job 专门服务于docker client，接收并调试分发docker client发送的请求 通过gorilla/mux创建路由器，添加路由项 每一个请求，都会创建一个全新的goroutine来服务。 服务过程： 1. 读取请求内部 2. 解析请求 3. 匹配路由 4. 调用相应的handler来处理 5. 应答响应 engine 存储着容器信息，管理着大部分job的执行 负责完成docker daemon退出前的所有善后工作 job engine内部最基本的工作执行单元 job接口的设计，与unix进程相仿，有名称、运行时参数、环境变量、标准输入与输出、标准错误、返回状态等 job运行函数Run用来执行job本身   Docker Registry 存储容器镜像的仓库 容器创建时，用来初始化容器rootfs的文件系统内容，将大量的容器镜像汇集在一起，并为分散的daemon提供镜像服务 graph 容器镜像的保管者 driver 驱动模块，可以实现docker运行环境的定制，定制的维度主要有网络环境、存储方式以及容器执行方式 分为三类驱动： 1. graph driver 主要用于完成容器镜像的管理，包括下载、存储、上传，也包括本地构建的存储 2. network driver 容器网络环境的配置，包括创建网桥、分配网络接口资源，分配ip、端口并与宿主机做nat端口映射，设置容器防火墙策略等 3. exec driver 执行驱动，负责创建容器运行时的命名空间、容器使用资源的统计与限制、容器内部进程的真正运行等 libcontainer 独立的容器管理解决方案，抽象了linux的内核特性（namespace，cgroups，capababilities等），并提供完整明确的接口给docker daemon Docker Container 服务交付的最终体现   docker cli  启动过程： 加载配置、创建客户端、执行命令（访问docker server）  docker daemon  启动过程： 加载配置、创建engine、设置信号、加载内建函数（网络初始化函数、api服务处理函数、事件和日志处理函数、版本和registry授权和搜索函数）、goroutine创建daemon对象，加载功能函数，通知服务启动信号、创建serverapi的job，启动监听服务  单独分析创建daemon对象 &gt; 创建daemon对象，通过eng的Hack_SetGlobalVar将daemon指针保存在了map中，key为：httpapi.
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/kuber/docker-src/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  
    <article>
  <header>
    <h2><a href="http://wonder.zxcsoft.com/post/kuber/kuber_myapp/">kuber应用搭建</a></h2>

    <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>2018-07-29</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/dreammap">dreammap</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="http://wonder.zxcsoft.com/tags/kubernetes">kubernetes</a>
    
  </div>
  
  

</div>

  </header>

  <p>
  dreammap搭建 1. 应用打包docker容器 1.1 前端界面  dockerfile  from nginx:1.15.2-alpine COPY wonder-dream /usr/share/nginx/html EXPOSE 80   build.sh  function build(){ cp -rp ../dist/wonder-dream . docker rmi wonderdream:v0.0.1 docker build -t wonderdream:v0.0.1 . } function run(){ docker run -itd -p 8091:80 wonderdream:v0.0.1 } function tar(){ docker save -o wonder_ng.tgz wonderdream:v0.0.1 } $1   kuber部署yaml，这里就用service实现了访问，没有做单独的ingress  apiVersion: v1 kind: Service metadata: name: wonderng labels: app: wonderng spec: type: LoadBalancer ports: - port: 80 name: http selector: app: wonderng --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: wonderdream-v0.
  </p>

  
  <footer>
    <a href="http://wonder.zxcsoft.com/post/kuber/kuber_myapp/">Read more<i class="fa fa-angle-double-right fa-fw"></i></a>
  </footer>
  
</article>

  

  


<nav class="pagination" role="pagination">
  
  <i class="fa fa-chevron-left"></i>
  
  <span>&nbsp;1 / 5&nbsp;</span>
  
  <a href="http://wonder.zxcsoft.com/page/2/"><i class="fa fa-chevron-right"></i></a>
  
</nav>



</div>

</div>
</div>
<script src="http://wonder.zxcsoft.com/js/ui.js"></script>






</body>
</html>

