<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on miracle of light</title>
    <link>http://wonder.zxcsoft.com/post/</link>
    <description>Recent content in Posts on miracle of light</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-CN</language>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Mon, 05 Nov 2018 11:01:00 +0800</lastBuildDate>
    
	<atom:link href="http://wonder.zxcsoft.com/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>keepalived心跳检测</title>
      <link>http://wonder.zxcsoft.com/post/linux/keepalived/keeplived/</link>
      <pubDate>Mon, 05 Nov 2018 11:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/linux/keepalived/keeplived/</guid>
      <description>keepalived 心跳检测 keepalived版本：1.4.5
流程说明  keepalived启动后，会fork出两个子进程：一个用于心跳检测，一个用于vrrp主结点选取（本文暂不细说） 心跳检测功能说明：读取keepalive.conf配置，解析vs（virtual server）rs(real server)，检测rs服务是否正常（创建sockert连接：只创建连接，连接成功就表示服务正常，不发心跳），服务正常，则配置ipvs
 keepalived任务调度说明（keepalived的心跳检测是单线程串行处理的）：
 keepalive心跳检测程序有这几个任务队列：event,child,ready,read,write,timer。队列的优先级从左到右从高到低（因为是串行处理，最先调度的优先级最高）。 心跳检测过程，只会涉及到timer,write,ready队列。 所有的任务都是由主线程来调度的，调度方法为：  如果event中有任务，则直接从event中取出执行 如果child中有任务，则直接从child中取出执行 如果ready中有任务，则直接从ready中取出执行 这里有一个至多1秒的休眠等待（遍历所有队列，取出离当前时间最近的任务的时间，和当前时间做差，如果大于1秒，则休眠1秒，如果小于，则按该时间休眠） 如果read中有任务，并且当中的socket fd可读，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中）。如果当前任务的调度时间大于当前时间，则将任务设置为超时，放入ready队列中 如果write中有任务，并且当中的socket fd可写，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中）。如果当前任务的调度时间大于当前时间，则将任务设置为超时，放入ready队列中 如果timer中有任务，并且调度时间大于或等于当前时间，则取出该任务放到ready队列中（所有满足条件的都会放入ready队列中） 取出ready中第一个任务并执行，没有取到任务则返回到第一步继续执行。   单组心跳检测流程（配置文件加载完，一组心跳检测就会生成一个任务A放入timer队列中）：
 一次心跳检测，会有两个任务
 任务A：创建socket连接。根据等到的fd创建任务B放到writer队列中。 任务B：读取socket fd连接状态，根据检测结果配置ipvs。创建一个新的任务A，放入timer队列中。 一组心跳检测就相当于检测一只鸡生蛋的过程。读取完配置文件，发现有100组心跳检测，就好比有100只要检测的鸡（任务A），这个时候都放在鸡窝（timer队列）中，每只鸡上都挂了个时间：生蛋的时间（调度时间），时间到了才调度。详细说明一只鸡（一组心跳检测）的处理流程：  调度者扫描timer队列（当然还有其它队列），发现鸡上的时间到了，把鸡取出来，放到产房（ready队列）中（因为有可能有多个满足条件的，所以一次都放到ready队列中） 调度者从ready队列中取出任务（当前是任务A），执行： 它完成下蛋，把蛋+检测方案（任务B）放到质检房（writer队列）中，同时写上超时时间（鸡蛋坏掉的时间）。 调度者扫描writer队列，发现有蛋了，将它放到ready队列中（任务B）（所有满足条件的），同时检查超时时间，如果时间已经过了（鸡蛋坏了），则修改任务状态为超时。 调度者从ready队列中取出任务（当前是任务B），执行： 先检查任务是不是超时，如果超时了，则直接认定检查失败。否则根据方案检测蛋，如果通过就更新该条ipvs，不通过就删除该条ipvs。然后再把鸡放回去（生成任务A&amp;rsquo;），写下下一次下蛋时间（调度时间），放到timer队列中   ipvs配置示例：
  TCP 10.10.88.98:3306 wlc persistent 1800 -&amp;gt; 10.244.1.222:3306 Masq 1 0 0 TCP 10.10.88.98:9104 wlc persistent 1800 -&amp;gt; 10.244.1.222:9104 Masq 1 0 0  问题说明 程序配置更新了(配置文件中vs-rs的配置更新了)，keepalived也有不停的在更新配置文件的日志（keepalived已经收到信号重新加载了配置文件），但ipvs并没有生效（手工检查rs服务是正常的，但并没有vs-rs的ipvs配置）</description>
    </item>
    
    <item>
      <title>go源码学习</title>
      <link>http://wonder.zxcsoft.com/post/language/go/go-src/</link>
      <pubDate>Sun, 26 Aug 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/language/go/go-src/</guid>
      <description>启动过程  初始化参数 设置argc，argv 初始化系统 设置maxproc 初始化调度器
 初始化栈分配器stack 初始化内存分配器malloc 公共初始化
 处理命令行参数、环境变量：gorags，goenvs
 垃圾回收初始化gcinit
  runtime.main
 初始化runtime包中的所有init函数 启动垃圾回收 执行所有用户包中的init 进入main.main，用户逻辑入口   内存分配  go内存空间结构
 页所属 spans 512MB | gc标记位图 bitmap 32GB | 用户内存分配 arena 512GB （后面的空间为可能的最大空间）  分配器将内存为两种：span内存块，object内存对象
 使用tcmalloc来管理内存
 cache 每个线程都会绑定一个cache，用于无锁object分配 central 为所有cache提供切分好的后备span heap 管理闲置的span，需要时向系统申请新内存
 优先使用cache来分配对象，如果不足，再从central中优先找现有的span检查是否有可用空间，再不足，才到heap中申请span
  内存分配
 golang编译器支持逃逸分析(escape analysis)，编译期通过构建调用图来分析局部变量是否会被外部引用，从而决定是否可直接分配在栈上 编译参数 -gcflags &amp;ldquo;-m&amp;rdquo; 可输出编译优化信息  内存回收
 以span为单元，检查span内的object是否全部释放，将原本就为空的span转移到central.nonempty，将收回的span交还给heap。同时会尝试合并相邻的空的span  内存释放</description>
    </item>
    
    <item>
      <title>kbuernetes docs 学习</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kuber_docs/</link>
      <pubDate>Thu, 23 Aug 2018 19:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kuber_docs/</guid>
      <description>kubernetes docs 学习  参考 http://docs.kubernetes.org.cn/251.html 对应源地址 https://kubernetes.feisky.xyz/zh/  kubernetes架构  etcd 保存整个集群的状态 apiserver 提供资源操作的唯一入口，并提供认证、授权、访问控制、api注册和发现等机制 controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等 scheduler负责资源的调度，按照预定的调度策略将pod调度到相应的机器上 kubelet 负责维护容器的生命周期，同时也负责volume（cvi）和网络（cni）的管理 container runtime负责镜像管理以及pod和容器的真正运行（cri） kube-proxy 负责为service提供cluster内部的服务发现和负载均衡  除了这些核心组件，还有些扩展的add-ons： * kube-dns负责为整个集群提供dns服务 * ingress controller为服务提供外网入口 * heapster提供资源监控 * dashboard提供gui * fedreation提供跨可用区的集群 * fluentd-elasticsearch提供集群日志采集、存储与查询
kuber分层架构  核心层：kubernetes最核心的功能，对外提供api构建高层的应用，对内提供插件式应用执行环境 应用层：部署（无状态应用、有状态应用、批处理任务、集群应用等）和路由（服务发现、dns解析等） 管理层：系统度量（如基础设置、容器和网络的度量），自动化（如自动扩展、动态Provision等）以及策略管理（RBAC，quota，psp，networkpolicy等） 接口层：kubectl命令行工具、客户端sdk以及集群联邦 生态系统：在接口层之上的庞大容器集群管理调度的生态系统，可以划分两个  kubernetes外部：日志、监控、配置管理、ci,cd,workflow,faas,ots应用,chatops kubernetes内部：cri,cni,cvi,镜像仓库，cloud provider,集群自身的配置和管理等   kubernetse的设计理念 api设计原则  所有api应该是声明式的（比如设置副本数为3，运行多次也没问题，而给副本数加1，运行多次就不对了） api对象是彼此互补而且可以组合的 高层api以操作意图为基础设计（从业务出发，而不是过早的从技术实现出发） 低层api根据高层api的控制需要设计（以需求为基础，尽量抵抗受技术实现影响的诱惑） 尽量避免简单封装，不要有在外部api无法显式知道的内部隐藏的机制（简单的封装实际没有提供新功能，反而增加对所封装api的依赖性。内部隐藏的机制不利于系统维护的设计方式） api操作复杂试与对象数量成正比 api对象状态不能依赖于网络连接状态（对象状态能应对网络不稳定） 尽量避免让操作机制依赖于全局状态，因为在分布式系统中要保证全局状态的同步是非常困难  控制机制设计原则  控制逻辑应该只依赖于当前状态 假设任何错误的可能，并做差错处理 尽量避免复杂状态机，控制逻辑不要依赖无法监控的内部状态 假设任何操作都可能被任何操作对象拒绝，甚至被错误解析（保证出现错误的时候，操作级别的错误不会影响到系统稳定性） 每个模块都可以在出错后自动恢复 每个模块都可以在必要时优雅的降级服务（划分清楚基本功能和高级功能，保证基本功能不会依赖高级功能，这样就保证了不会因为高级功能出现故障而导致整个模块崩溃）  kuber api对象  pod pod内的容器共享网络和文件系统，可以通过进程间通信和文件共享这种简单高效的方式组合完成服务。比如，一个nginx容器用来发布软件，另一个容器专门用来从源仓库做同步 pod是所有业务类型的基础，k8s中业务主要分四类：  Deployment：长期伺服型（long-runing） Job：批处理型（batch） DaemonSet：节点后台支撑型（node-daemon） PetSet：有状态应用型（stateful application）    pod特征：  共享ipc、network、utc namespace的容器 所有pod内容器都可以访问共享的Volume，可以访问共享数据 pod一旦调度后就和node绑定，即使node挂掉也不会重新调度，推荐使用deployments、daemonsets等控制器来容错 优雅终止：pod删除的时候，先给其内的进程发送sigterm，等待一段时间（graceperiod）后才强制停止依然还在运行的进程 特权容器（通过SecurityContext配置）具有改变系统配置的权限（在网络插件中大量应用）    复制控制器（Replication Controller，RC） RC是k8s集群中最早的保证pod高可用的api对象，监控运行中的pod来保证集群中运行指定数目的pod副本。只适用于长期伺服型的业务类型</description>
    </item>
    
    <item>
      <title>oracle锁表问题</title>
      <link>http://wonder.zxcsoft.com/post/oracle/oracle_lock/</link>
      <pubDate>Tue, 21 Aug 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/oracle/oracle_lock/</guid>
      <description> 查询oralce锁表 --查询锁表会话 SELECT s.username, decode(l.type,&#39;TM&#39;,&#39;TABLE LOCK&#39;, &#39;TX&#39;,&#39;ROW LOCK&#39;, NULL) LOCK_LEVEL, o.owner,o.object_name,o.object_type, s.sid,s.serial#,s.terminal,s.machine,s.program,s.osuser FROM v$session s,v$lock l,dba_objects o WHERE l.sid = s.sid AND l.id1 = o.object_id(+) AND s.username is NOT Null --杀死事务 alter system kill session&#39;SID,SERIAL#&#39;; --查询锁表的sql语句 SELECT l.session_id sid, s.serial#, l.locked_mode, l.oracle_username, s.user#, l.os_user_name,s.machine, s.terminal,a.sql_text, a.action FROM v$sqlarea a,v$session s, v$locked_object l WHERE l.session_id = s.sid AND s.prev_sql_addr = a.address ORDER BY sid, s.serial#;  </description>
    </item>
    
    <item>
      <title>dart use</title>
      <link>http://wonder.zxcsoft.com/post/web/dart/</link>
      <pubDate>Sun, 12 Aug 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/web/dart/</guid>
      <description> dart use d3.js import &#39;dart:html&#39;; import &#39;package:js/js.dart&#39; as js; void main() { var dee3 = js.context.d3; var dataset = js.array([ 5, 10, 15, 20, 25 ]); dee3.select(&amp;quot;body&amp;quot;).selectAll(&amp;quot;p&amp;quot;) .data(dataset) .enter() .append(&amp;quot;p&amp;quot;) .text((d, i, context) =&amp;gt; d); }  </description>
    </item>
    
    <item>
      <title>fluentd使用说明</title>
      <link>http://wonder.zxcsoft.com/post/kuber/fluentd/</link>
      <pubDate>Sun, 05 Aug 2018 10:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/fluentd/</guid>
      <description>fluentd配置说明  参考：https://docs.fluentd.org/v1.0/articles/filter-plugin-overview  filter配置说明  filter根据tag来匹配，可有多个filter对应同一个tag，处理按配置的顺序依次处理  筛选消息中包括cool的
&amp;lt;filter foo.bar&amp;gt; @type grep regexp1 message cool &amp;lt;/filter&amp;gt;  目前自带的filter有4个  filter_record_transformer 报文转换  语法格式：
&amp;lt;record&amp;gt; NEW_FIELD NEW_VALUE &amp;lt;/record&amp;gt;  tag的处理方法：
//tag_parts[N] 表示tag的第N个部分 tag_prefix[0] = debug tag_suffix[0] = debug.my.app tag_prefix[1] = debug.my tag_suffix[1] = my.app tag_prefix[2] = debug.my.app tag_suffix[2] = app  &amp;lt;filter foo.bar&amp;gt; @type record_transformer &amp;lt;record&amp;gt; hostname &amp;quot;#{Socket.gethostname}&amp;quot; #给报文增加两个域：hostname，tag tag ${tag} avg ${record[&amp;quot;total&amp;quot;] / record[&amp;quot;count&amp;quot;]} ##增加一个avg域，计算报文中total和count的除数 message yay, ${record[&amp;quot;message&amp;quot;]} ## 给message域增加个前缀 &amp;lt;/record&amp;gt; &amp;lt;/filter&amp;gt;   filter_grep 报文筛选  &amp;lt;filter foo.</description>
    </item>
    
    <item>
      <title>kuber log analysis</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kuber-logs/</link>
      <pubDate>Sun, 05 Aug 2018 10:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kuber-logs/</guid>
      <description>kubernetes日志管理 参考资料：https://logz.io/blog/kubernetes-log-analysis/
1. 安装fluentd  参考官方文档：https://docs.fluentd.org/v1.0/articles/install-by-rpm#redhat-/-centos
 td-agent是对fluentd的封装，并加入了管理工具，比如java有集成的应用包
  curl -L https://toolbelt.treasuredata.com/sh/install-redhat-td-agent3.sh | sh #启动td-agent systemctl start td-agent #安装td-agent es插件 sudo /usr/sbin/td-agent-gem install fluent-plugin-elasticsearch --no-document  2. 配置说明  配置td-agent： 备份 /etc/td-agent/td-agent.conf  ## 增加一个测试的日志输入，用于测试解析日志并写入es &amp;lt;source&amp;gt; @type http @id input_http port 42185 tag http.test &amp;lt;/source&amp;gt; # 配置将收到的日志输入到控制台 &amp;lt;match **&amp;gt; @type stdout @id output_stdout &amp;lt;/match&amp;gt; # 配置将日志写入es &amp;lt;match http.test&amp;gt; #一个source的tag只会匹配一个match，有多个时，不会都匹配 @type elasticsearch logstash_format true host localhost port 9200 #hosts host1:port1,host2:port2,host3:port3 # or #hosts https://customhost.</description>
    </item>
    
    <item>
      <title>rss tools</title>
      <link>http://wonder.zxcsoft.com/post/tools/rss_tools/</link>
      <pubDate>Sat, 04 Aug 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/tools/rss_tools/</guid>
      <description>rss 开源服务搭建，基于kuber+coredns+traefik 1.下载镜像 docker pull miniflux/miniflux:2.0.10 docker pull postgres:11-alpine  2.部署pg 1. 创建本地存储 apiVersion: v1 kind: PersistentVolume metadata: name: local-pv-1 labels: type: local spec: capacity: storage: 10Gi accessModes: - ReadWriteOnce hostPath: path: /data/pv/1  2. 创建存储使用申明  pvc到pv的绑定是，自动完成的，并且绑定后就是一对一的绑定，不会再改变。绑定考虑的是空间大小，如果没有合适的，会挂起，直到有合适的存储。kubectl get pvc 能看到具体的绑定情况 pvc的大小可以比pv小，用来实现存储大小的控制  apiVersion: v1 kind: PersistentVolumeClaim metadata: name: pg-pv-claim labels: app: postgres spec: accessModes: - ReadWriteOnce resources: requests: storage: 10Gi  3. 创建应用 apiVersion: extensions/v1beta1 kind: Deployment metadata: name: pg-11 spec: replicas: 1 template: metadata: labels: app: pg-11 spec: containers: - name: pg image: postgres:11-alpine imagePullPolicy: IfNotPresent ports: - containerPort: 5432 env: - name: POSTGRES_PASSWORD value: wonder # 虽然pgdata目录没变，但要设置，目的是为了触发initdb调用 name: PGDATA value: /var/lib/postgresql/data/pgdata volumeMounts: - name: pg-pv-storage mountPath: /var/lib/postgresql/data/pgdata volumes: - name: pg-pv-storage persistentVolumeClaim: claimName: pg-pv-claim  4.</description>
    </item>
    
    <item>
      <title>docker源码分析</title>
      <link>http://wonder.zxcsoft.com/post/kuber/docker-src/</link>
      <pubDate>Wed, 01 Aug 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/docker-src/</guid>
      <description>docker源码分析 读《docker源码分析》整理
容器说明  先有进程，后有容器 父进程通过fork创建子进程时，使用namespaces技术（CLONE_NEWNS,CLONE_NEWUTS,CLONE_NEWIPC,CLONE_PID,CLONE_NEWNET），实现子进程和父进程以及其它进程之间的命名空间的隔离 子进程创建完毕后，使用cgroups技术来处理进程，实现进程资源限制 这样，进程所处的“隔离”环境才真正建立，此时容器真正诞生  docker架构  docker有如下模块：
 DockerClient 发起容器管理请求，请求最终发往DockerDaemon DockerDaemon  接收请求，所有的任务由engine来完成，每一项工作都以job形式存在 管理所有的容器 大致分为三部分：  docker server 它本身是一个名为serveapi的job 专门服务于docker client，接收并调试分发docker client发送的请求 通过gorilla/mux创建路由器，添加路由项 每一个请求，都会创建一个全新的goroutine来服务。 服务过程： 1. 读取请求内部 2. 解析请求 3. 匹配路由 4. 调用相应的handler来处理 5. 应答响应 engine 存储着容器信息，管理着大部分job的执行 负责完成docker daemon退出前的所有善后工作 job engine内部最基本的工作执行单元 job接口的设计，与unix进程相仿，有名称、运行时参数、环境变量、标准输入与输出、标准错误、返回状态等 job运行函数Run用来执行job本身   Docker Registry 存储容器镜像的仓库 容器创建时，用来初始化容器rootfs的文件系统内容，将大量的容器镜像汇集在一起，并为分散的daemon提供镜像服务 graph 容器镜像的保管者 driver 驱动模块，可以实现docker运行环境的定制，定制的维度主要有网络环境、存储方式以及容器执行方式 分为三类驱动： 1. graph driver 主要用于完成容器镜像的管理，包括下载、存储、上传，也包括本地构建的存储 2. network driver 容器网络环境的配置，包括创建网桥、分配网络接口资源，分配ip、端口并与宿主机做nat端口映射，设置容器防火墙策略等 3. exec driver 执行驱动，负责创建容器运行时的命名空间、容器使用资源的统计与限制、容器内部进程的真正运行等 libcontainer 独立的容器管理解决方案，抽象了linux的内核特性（namespace，cgroups，capababilities等），并提供完整明确的接口给docker daemon Docker Container 服务交付的最终体现   docker cli  启动过程： 加载配置、创建客户端、执行命令（访问docker server）  docker daemon  启动过程： 加载配置、创建engine、设置信号、加载内建函数（网络初始化函数、api服务处理函数、事件和日志处理函数、版本和registry授权和搜索函数）、goroutine创建daemon对象，加载功能函数，通知服务启动信号、创建serverapi的job，启动监听服务  单独分析创建daemon对象 &amp;gt; 创建daemon对象，通过eng的Hack_SetGlobalVar将daemon指针保存在了map中，key为：httpapi.</description>
    </item>
    
    <item>
      <title>kuber应用搭建</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kuber_myapp/</link>
      <pubDate>Sun, 29 Jul 2018 16:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kuber_myapp/</guid>
      <description>dreammap搭建 1. 应用打包docker容器 1.1 前端界面  dockerfile  from nginx:1.15.2-alpine COPY wonder-dream /usr/share/nginx/html EXPOSE 80   build.sh  function build(){ cp -rp ../dist/wonder-dream . docker rmi wonderdream:v0.0.1 docker build -t wonderdream:v0.0.1 . } function run(){ docker run -itd -p 8091:80 wonderdream:v0.0.1 } function tar(){ docker save -o wonder_ng.tgz wonderdream:v0.0.1 } $1   kuber部署yaml，这里就用service实现了访问，没有做单独的ingress  apiVersion: v1 kind: Service metadata: name: wonderng labels: app: wonderng spec: type: LoadBalancer ports: - port: 80 name: http selector: app: wonderng --- apiVersion: extensions/v1beta1 kind: Deployment metadata: name: wonderdream-v0.</description>
    </item>
    
    <item>
      <title>traefik服务搭建</title>
      <link>http://wonder.zxcsoft.com/post/kuber/traefik/</link>
      <pubDate>Sun, 29 Jul 2018 16:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/traefik/</guid>
      <description>Traefik服务使用 尽管svc有了负载均衡功能，可以简单通过LoadBalance来实现，但功能相对简单，而且有多个服务的时候，不好统一管理，而traefik是一个反向代理，可以像nginx一样配置相应的服务代理功能，并增加了检查服务是否可用、pod状态等功能，动态的更新配置
1.Traefik的部署  参考官方文档：https://docs.traefik.io/user-guide/kubernetes/
  创建角色：因为traefik需要访问kuber来获取服务等的状态信息  kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress-controller rules: - apiGroups: - &amp;quot;&amp;quot; resources: - services - endpoints - secrets verbs: - get - list - watch - apiGroups: - extensions resources: - ingresses verbs: - get - list - watch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1beta1 metadata: name: traefik-ingress-controller roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: traefik-ingress-controller subjects: - kind: ServiceAccount name: traefik-ingress-controller namespace: default   创建服务 traefik本身也是一种服务，和其它服务一样，80是工作端口（服务分发），8080是ui端口，可查看当前情况  apiVersion: v1 kind: ServiceAccount metadata: name: traefik-ingress-controller namespace: default --- kind: Deployment apiVersion: extensions/v1beta1 metadata: name: traefik-ingress-controller namespace: default labels: k8s-app: traefik-ingress-lb spec: replicas: 1 selector: matchLabels: k8s-app: traefik-ingress-lb template: metadata: labels: k8s-app: traefik-ingress-lb name: traefik-ingress-lb spec: serviceAccountName: traefik-ingress-controller terminationGracePeriodSeconds: 60 containers: - image: traefik:v1.</description>
    </item>
    
    <item>
      <title>docker 安装 oracle</title>
      <link>http://wonder.zxcsoft.com/post/oracle/docker_ora/</link>
      <pubDate>Thu, 26 Jul 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/oracle/docker_ora/</guid>
      <description>docker centos7中安装oracle 参考：
 https://blog.csdn.net/sql_ican/article/details/77749981 #脚本测试是可用的 http://www.cnblogs.com/wq3435/p/6523840.html #ora配置说明可参考  注意问题 swap 问题 oracle安装要求swap空间的，所以docker对应的宿主机器上swap要开，因为docker &amp;ndash;privileged模式下用的是主机的swap空间，可在安装完成后，再关swap</description>
    </item>
    
    <item>
      <title>oracle问题分析</title>
      <link>http://wonder.zxcsoft.com/post/oracle/oracle_ora/</link>
      <pubDate>Thu, 26 Jul 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/oracle/oracle_ora/</guid>
      <description>oracle临时表空间满问题 --查询表空间使用情况 select * from ( Select a.tablespace_name, to_char(a.bytes/1024/1024,&#39;99,999.999&#39;) total_bytes, to_char(b.bytes/1024/1024,&#39;99,999.999&#39;) free_bytes, to_char(a.bytes/1024/1024 - b.bytes/1024/1024,&#39;99,999.999&#39;) use_bytes, to_char((1 - b.bytes/a.bytes)*100,&#39;99.99&#39;) || &#39;%&#39;use from (select tablespace_name, sum(bytes) bytes from dba_data_files group by tablespace_name) a, (select tablespace_name, sum(bytes) bytes from dba_free_space group by tablespace_name) b where a.tablespace_name = b.tablespace_name union all select c.tablespace_name, to_char(c.bytes/1024/1024,&#39;99,999.999&#39;) total_bytes, to_char( (c.bytes-d.bytes_used)/1024/1024,&#39;99,999.999&#39;) free_bytes, to_char(d.bytes_used/1024/1024,&#39;99,999.999&#39;) use_bytes, to_char(d.bytes_used*100/c.bytes,&#39;99.99&#39;) || &#39;%&#39;use from (select tablespace_name,sum(bytes) bytes from dba_temp_files group by tablespace_name) c, (select tablespace_name,sum(bytes_cached) bytes_used from v$temp_extent_pool group by tablespace_name) d where c.</description>
    </item>
    
    <item>
      <title>nginx配置</title>
      <link>http://wonder.zxcsoft.com/post/linux/nginx/</link>
      <pubDate>Thu, 26 Jul 2018 19:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/linux/nginx/</guid>
      <description> nginx 正向代理配置 server { resolver 114.114.114.114; #指定DNS服务器IP地址 listen 80; location / { proxy_pass http://$http_host$request_uri; #设定代理服务器的协议和地址 proxy_set_header HOST $http_host; proxy_buffers 256 4k; proxy_max_temp_file_size 0k; proxy_connect_timeout 30; proxy_send_timeout 60; proxy_read_timeout 60; proxy_next_upstream error timeout invalid_header http_502; } } server { resolver 114.114.114.114; #指定DNS服务器IP地址 listen 443; location / { proxy_pass https://$host$request_uri; #设定代理服务器的协议和地址 proxy_buffers 256 4k; proxy_max_temp_file_size 0k; proxy_connect_timeout 30; proxy_send_timeout 60; proxy_read_timeout 60; proxy_next_upstream error timeout invalid_header http_502; } }  </description>
    </item>
    
    <item>
      <title>prometheus源码分析</title>
      <link>http://wonder.zxcsoft.com/post/prometheus/prometheus-src/</link>
      <pubDate>Thu, 26 Jul 2018 19:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/prometheus/prometheus-src/</guid>
      <description>待完善&amp;hellip;</description>
    </item>
    
    <item>
      <title>kuber单机部署</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kuber_sign/</link>
      <pubDate>Wed, 25 Jul 2018 20:00:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kuber_sign/</guid>
      <description>kuber单机部署 由于在阿里上只有一台，又不准备用minikube，所以单机部署一个
1.安装docker wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-18.06.0.ce-3.el7.x86_64.rpm yum install docker-ce-18.06.0.ce-3.el7.x86_64.rpm  2.安装etcd  生成根证书  { &amp;quot;key&amp;quot;: { &amp;quot;algo&amp;quot;: &amp;quot;rsa&amp;quot;, &amp;quot;size&amp;quot;: 4096 }, &amp;quot;names&amp;quot;: [ { &amp;quot;O&amp;quot;: &amp;quot;wonder&amp;quot;, &amp;quot;OU&amp;quot;: &amp;quot;wonder Security&amp;quot;, &amp;quot;L&amp;quot;: &amp;quot;Sh&amp;quot;, &amp;quot;ST&amp;quot;: &amp;quot;Sh&amp;quot;, &amp;quot;C&amp;quot;: &amp;quot;CN&amp;quot; } ], &amp;quot;CN&amp;quot;: &amp;quot;wonder-root-ca&amp;quot; }  3.自动化脚本配置如下 #!/bin/zsh . ./config/env function set_path(){ for IP in $MASTER;do ssh root@$IP &#39;echo &amp;quot;export PATH=\$PATH:/opt/kubernetes/bin/&amp;quot; &amp;gt;&amp;gt; ~/.bash_profile&#39; done } function set_hosts(){ ##set hosts for IP in $MASTER $NODE;do scp .</description>
    </item>
    
    <item>
      <title>goadesign 学习之adder</title>
      <link>http://wonder.zxcsoft.com/post/goa/goa_use/</link>
      <pubDate>Sun, 22 Jul 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/goa/goa_use/</guid>
      <description>goadesign 学习  一次接触中，了解到了goa，根据dsl做巧妙的翻译，自动完成统一代码的生成
 github上搜索goadesign，可以看到他有的代码库，出于学习，我把它的样例库下载下来了，我决定从样例代码开始，结合官方的文档来学习
先从第一个例子开始  第一个是加法服务，adder目录只有两个go文件，其中一个还在报错（其实是程序自动生成的文件，只是里面有自己定制的代码，所以保留了  // adder/design/design.go var _ = API(&amp;quot;adder&amp;quot;, func() { //api定义说明，一个文件只可以有一个api Title(&amp;quot;The adder API&amp;quot;) Description(&amp;quot;A teaser for goa&amp;quot;) Host(&amp;quot;localhost:8080&amp;quot;) Scheme(&amp;quot;http&amp;quot;) }) var _ = Resource(&amp;quot;operands&amp;quot;, func() { //资源说明，resource对应一个service Action(&amp;quot;add&amp;quot;, func() { //动作说明，api请求动作 Routing(GET(&amp;quot;add/:left/:right&amp;quot;)) //定义访问地址格式 Description(&amp;quot;add returns the sum of the left and right parameters in the response body&amp;quot;) Params(func() { //定义请求url中参数说明 Param(&amp;quot;left&amp;quot;, Integer, &amp;quot;Left operand&amp;quot;) Param(&amp;quot;right&amp;quot;, Integer, &amp;quot;Right operand&amp;quot;) }) Response(OK, &amp;quot;text/plain&amp;quot;) //定义应答报文样式 }) })   根据design文件生成代码  goagen bootstrap -d github.</description>
    </item>
    
    <item>
      <title>goadesign 学习之dsl</title>
      <link>http://wonder.zxcsoft.com/post/goa/goa_dsl/</link>
      <pubDate>Sun, 22 Jul 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/goa/goa_dsl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>golang 总结</title>
      <link>http://wonder.zxcsoft.com/post/language/go/quest/</link>
      <pubDate>Wed, 18 Jul 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/language/go/quest/</guid>
      <description> Ready go 1. goroutine  goroutine 对应的用户态线程，而不是系统线程，调度是由golang自己来调度的 golang采用的是一种多对多的方案，m个用户线程对应n个系统线程 golang有3个角色：  M：代表系统线程，由操作系统管理 G：goroutine的实体，包括的调用栈，重要的调度信息 P：衔接M和G的调度上下文，由GOMAXPROCS决定，一般和核心数对应。每个P会将goroutine从一个就绪的队列中做pop操作，为了减小锁的竞争，通常情况下每个P会负责一个队列   </description>
    </item>
    
    <item>
      <title>读《微服务架构与实践》总结</title>
      <link>http://wonder.zxcsoft.com/post/book/micro/</link>
      <pubDate>Tue, 17 Jul 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/book/micro/</guid>
      <description> 微服务的特征  业务独立性 轭人自主性 单一职责 轻量级通信
 服务作为组件
 围绕业务组织团队
 关注产品而非项目
 技术多样性
 业务数据独立
 基础设施自动化
 演进式架构
  构建微服务考虑的问题  任务拆分
尽早将开发、测试、部署、运维、监控的流水线打通，才能帮助团队更好的驾驭微服务
 同一时间聚焦一个任务 能对每次完成的部分做持续集成 整体的进度容易追踪  一般任务分为如下几个过程： * 服务实现 * 代码测试与静态检查 * Docker镜像构建 * docker镜像部署 * 功能迭代 * 日志聚合 * 监控与告警 * 持续集成与交付
  微服务设计 开发  独立代码库 服务说明文件  服务介绍 服务维护者 服务可用期 定义环境：生产环境、类生产环境、测试环境 开发说明：如果搭建开发环境、如何运行服务、如何定位问题 测试说明：测试策略、如何运行测试、如果查看测试结果 构建说明：集成访问的url、集成流程描述、构建的部署包 部署说明：如何部署到不同环境、部署后功能验证 运维说明：日志聚合的访问、告警信息的访问、监控信息的访问  代码所有权归团队：不能让代码只有一个人熟悉 有效的代码版本管理 代码静态检查工具 代码易于本地运行  测试  接口测试 测试的有效性  构建  每个服务都是一个可独立部署的业务单元  部署  部署环境说明  运维  监控 告警 日志聚合  微服务之前的通讯  同步通讯、异步通讯 rpc rest：资源、表述、状态转移、统一接口  get用来获取资源 post来新建资源 put来更新资源 delete来删除资源  hal  基于rest，但把每个资源分成三部分：状态、链接、子资源  消息队列  </description>
    </item>
    
    <item>
      <title>caddy</title>
      <link>http://wonder.zxcsoft.com/post/tools/caddy-src/</link>
      <pubDate>Fri, 29 Jun 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/tools/caddy-src/</guid>
      <description> caddy  caddy是个网站搭建工具  </description>
    </item>
    
    <item>
      <title>gorm源码分析</title>
      <link>http://wonder.zxcsoft.com/post/gorm/gorm-src/</link>
      <pubDate>Wed, 27 Jun 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/gorm/gorm-src/</guid>
      <description>总体分析  使用gorm的过程中，觉得它写的有意思，想了解下它的实现原理，所以就分析下源代码
 源码分析  由于这个是个库，并没有执行程序，看到目录下有main.go，所以就从这个开始
 1. main  定义了DB结构：
 Value //是接口类型，可放任何数据 Error //是记录错误 RowsAffected //记录生效行数 //单个db私有属性 db //定义的公共接口（Exec，Prepare，Query，QueryRow） //暂时不明白为什么选这4个，从open中可看出，go标准库中的sql.DB是实现了这个接口的 blockGlobalUpdate //记录全局更新标志 //从BlockGlobalUpdate函数中可看出，这个标志为true时，update或者delete没有where时，会报错 logMode //日志开关 2打开，1关闭 logger //自定义日志接口(print) search //search结构指针（用来拼接sql语句的） values //map[string]interface{} 可保存任何东西的map，暂时不知道要保存什么 //全局db属性 parent //父DB对象 callbacks //回调结构指针（记录了creates,updates,deletes,queries,rowQueries,processors类型的回调函数切片） dialet //sql格式化接口（针对不同的数据库定制化的差异） singularTable //bool类型，暂时不知道干什么的   open函数，调用go标准库打开数据库连接，设置默认日志，默认回调函数，并根据数据库连接类型，设置sql格式对象，并调用ping测试连接
后面就是一些DB的常规set和get方法，还有就是拼接sql的方法 * 通过set函数，可以看到，values里面保存的单个db中的修改化配置，clone的时候会复制过去，不是共用
main 大致过了一遍，对整个有点了解，再回看目录下的文件：
1. association 处理表关系的，针对外键 2. callback 开头的文件，处理回调函数的（等会重点看的） 3. dialect 开头的文件，处理各种数据库之前语法差异的 4. errors 定义了错误管理，所有的错误都在切片中 5. interface 定义了公共类的接口 6. join_table_handler 定义了n*n的表的关系接口 7.</description>
    </item>
    
    <item>
      <title>es 基本使用</title>
      <link>http://wonder.zxcsoft.com/post/es/esuse/</link>
      <pubDate>Mon, 25 Jun 2018 20:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/es/esuse/</guid>
      <description></description>
    </item>
    
    <item>
      <title>golang pprof使用</title>
      <link>http://wonder.zxcsoft.com/post/language/go/pprof/</link>
      <pubDate>Mon, 28 May 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/language/go/pprof/</guid>
      <description>启用pprof  带有http的服务，只需要引入 import _ &amp;quot;net/http/pprof&amp;quot; 就可以通过访问http://ip:port/debug/pprof 查看了
 没有http服务的应用，或者不想在原端口启用的，可像我这样实现根据配置启用（config是我自定义的配置包）
  import ( _ &amp;quot;net/http/pprof&amp;quot; &amp;quot;net/http&amp;quot; ) func InitModel() { var ppaddr string if config.HasModuleInit() { ppaddr = config.StringDefault(&amp;quot;ppaddr&amp;quot;, &amp;quot;&amp;quot;) if ppaddr != &amp;quot;&amp;quot; { go http.ListenAndServe(ppaddr, nil) } } }  pprof使用 1.代码优化 curl http://ip:port/debug/pprof/profile &amp;gt; /tmp/a.profile go tool pprof 可执行程序 /tmp/a.profile (pprof) top #可查看占用资源最多的函数  pprof各字段的含义依次是：  采样点执行时间 采样点落在该函数中的百分比 上一项的累积百分比 采样点落在该函数，以及被它调用的函数执行的总时间 采样点落在该函数，以及被它调用的函数中的百分比 函数名 文件名  pprof分析  / 访问根目录，里面有几个链接：</description>
    </item>
    
    <item>
      <title>记忆基数</title>
      <link>http://wonder.zxcsoft.com/post/selfupd/memorybase/</link>
      <pubDate>Wed, 16 May 2018 19:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/selfupd/memorybase/</guid>
      <description> 记忆基数  1 粉笔 2 鸭子 3 耳朵 4 红旗 5 秤钩 6 口哨 7 锄头 8 葫芦 9 气球 10 老师 11 双截棍 12 不倒翁 13  </description>
    </item>
    
    <item>
      <title>python 简单使用</title>
      <link>http://wonder.zxcsoft.com/post/language/python/pythi/</link>
      <pubDate>Fri, 11 May 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/language/python/pythi/</guid>
      <description>ipynb
jupyter notebook  </description>
    </item>
    
    <item>
      <title>tensorFlow 入门</title>
      <link>http://wonder.zxcsoft.com/post/tensorflow/learn_tensor/</link>
      <pubDate>Fri, 11 May 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/tensorflow/learn_tensor/</guid>
      <description>环境搭建 pyenv搭建  安装pyenv 安装pip virtualenv 创建虚拟环境
 python3 -m venv ./env 
 切换环境
 . env/bin/activate 
  conda搭建  安装anaconda3 创建虚拟环境
 conda create --name py3 python=3 
 环境切换
 source activate py3 
  tensorflow安装(下面操作都在python3环境下操作) ##我本地环境如下搭建 # conda create --name mytensor python=3.6 # source activate mytensor # source deactivate #退出环境 pip install tensorflow pip install tensorlayer  验证环境安装 import tensorflow as tf hello = tf.</description>
    </item>
    
    <item>
      <title>学习汇总</title>
      <link>http://wonder.zxcsoft.com/post/allmywonder/</link>
      <pubDate>Thu, 10 May 2018 20:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/allmywonder/</guid>
      <description>学习汇总 语言学习  go c php python java  go  kubernetes etcd istio tensorflow hugo grafana influxdb consul prometheus appdash nomad hystrix &amp;ndash; gin
 kit
 hydra
  php  laravel  python  tensorflow pytorch deepmind lab  js  nodejs codecombat  想做的事  读懂v8，用go来实现 使用tensorflow，完成智能识别 训练记忆力 es做为存储，d3来展示，完成思维图的整理与知识分析 使用kuber完成思维系统的搭建  工具收藏 linux shell on-my-zsh spf13-vim</description>
    </item>
    
    <item>
      <title>es 入门</title>
      <link>http://wonder.zxcsoft.com/post/es/esstart/</link>
      <pubDate>Fri, 27 Apr 2018 09:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/es/esstart/</guid>
      <description> es安装  官网下载 es https://www.elastic.co/downloads/elasticsearch  unzip elasticsearch-6.2.4.zip cd elasticsearch-6.2.4/config #修改集群名字和端口,数据目录等 vi elasticsearch.yml # 启动es cd elasticsearch-6.2.4/bin ./elasticsearch # 验证启动状态 curl http://127.0.0.1:9200  安装中文分词  参考 https://github.com/medcl/elasticsearch-analysis-ik
./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.2.4/elasticsearch-analysis-ik-6.2.4.zip
 es简单使用 创建一个index mapping（相当于一个表） curl -XPUT &#39;localhost:9200/wonderbook?pretty&#39; -H &#39;Content-type:application/json&#39; -d &#39; { &amp;quot;mappings&amp;quot;: { &amp;quot;articles&amp;quot;: { &amp;quot;properties&amp;quot;: { &amp;quot;title&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;, &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;}, &amp;quot;description&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;, &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;}, &amp;quot;tags&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;, &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;}, &amp;quot;date&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;date&amp;quot;}, &amp;quot;categories&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;, &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;}, &amp;quot;context&amp;quot;: {&amp;quot;type&amp;quot; : &amp;quot;text&amp;quot;, &amp;quot;analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;, &amp;quot;search_analyzer&amp;quot;: &amp;quot;ik_max_word&amp;quot;} } } } } &#39;  </description>
    </item>
    
    <item>
      <title>kbuernetes 学习</title>
      <link>http://wonder.zxcsoft.com/post/kuber/learn_kuber/</link>
      <pubDate>Fri, 27 Apr 2018 09:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/learn_kuber/</guid>
      <description>Kubernetes基本概念 Pod Pod是一组容器集合，他们共享IPC、Network 和 UTC namespace 例：
apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80  Node 运行pod的主机
Namespace 管理一组资源和对象
Service 应用服务的抽象，通过labels为应用提供负载均衡和服务发现。匹配labels为Pod IP和端口列表组成endpoints，由kube-proxy负责将服务IP负载均衡到这些endpoints上。 每个Service都会自动分配一个culster IP（仅在集群内部可访问的虚拟地址）和DNS名，其它容器可以通过该地址或DNS来访问服务
apiVersion: v1 kind: Service metadata: name: nginx spec: ports: - port: 8078 name: http targetPort: 80 protocol: TCP selector: app: nginx  Label 是识别Kurbernetes对象的标签，以key/value的方式附加到对象上。Label不提供唯一性，经常是很多对象（如Pods）都使用相同的label来标志具体的应用（如负载均衡时结点为的选择） label选择支持如下模式： * 等式： app=nginx 或 env!= production * 集合: env in (production, qa) * 多个label（他们之间是AND的关系）： app=nginx,env=test</description>
    </item>
    
    <item>
      <title>linux下socket的复用</title>
      <link>http://wonder.zxcsoft.com/post/linux/linux_socket/</link>
      <pubDate>Fri, 27 Apr 2018 09:01:00 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/linux/linux_socket/</guid>
      <description> linux下端口复用 SO_REUSEADDR可以用在以下四种情况下。 (摘自《Unix网络编程》卷一，即UNPv1)  当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你启动的程序的socket2要占用该地址和端口，你的程序就要用到该选项。
 SO_REUSEADDR允许同一port上启动同一服务器的多个实例(多个进程)。但每个实例绑定的IP地址是不能相同的。在有多块网卡或用IP Alias技术的机器可以测试这种情况。
 SO_REUSEADDR允许单个进程绑定相同的端口到多个socket上，但每个socket绑定的ip地址不同。这和2很相似，区别请看UNPv1。
 SO_REUSEADDR允许完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。
  ssh 代理隧道 #登录远端服务器，将远端服务的1521端口映射到本地的50001端口 ssh -b172.10.1.12 -L172.10.1.12:50001:127.0.0.1:1521 username@172.10.101.1 -CNf #将本地的9015端口映射到远端的9015端口：访问本地的9015就相当于本机访问远端的9015.数据转发 ssh -b172.10.1.12 -L172.10.1.12:9015:172.10.101.7:9015 username@127.0.0.1 -CNf #访问本机的9014，相当于通过101.1访问1.90的9014端口。 建立一个正向隧道 ssh -b172.10.1.12 -L:9014:11.0.1.90:9014 username@172.10.101.1 -CNf  </description>
    </item>
    
    <item>
      <title>istio初尝试</title>
      <link>http://wonder.zxcsoft.com/post/kuber/istio/</link>
      <pubDate>Thu, 26 Apr 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/istio/</guid>
      <description>说明  参考 http://istio.doczh.cn/
 安装istio  kubectl apply -f install/kubernetes/istio.yaml #如果出现 unable to recognize &amp;ldquo;install/kubernetes/istio.yaml&amp;rdquo; 的错误，删除后再重新执行一遍就好了
 部署bookinfo kubectl apply -f &amp;lt;(istioctl kube-inject -f bookinfo.yaml) #获取访问地址 export GATEWAY_URL=$(kubectl get po -l istio=ingress -n istio-system -o &#39;jsonpath={.items[0].status.hostIP}&#39;):$(kubectl get svc istio-ingress -n istio-system -o &#39;jsonpath={.spec.ports[0].nodePort}&#39;) #测试地址访问 curl -o /dev/null -s -w &amp;quot;%{http_code}\n&amp;quot; http://${GATEWAY_URL}/productpage  1.1 验证路由访问 #所有用户都访问v1 istioctl create -f route-rule-all-v1.yaml #jason用户登录访问v2 istioctl create -f route-rule-reviews-test-v2.yaml  1.2 记录日志 ##保存如下信息为 new_telemetry.</description>
    </item>
    
    <item>
      <title>kuber手工搭建</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kuber_onebyone/</link>
      <pubDate>Thu, 26 Apr 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kuber_onebyone/</guid>
      <description>准备工作 关闭selunix 关闭swap 作为node的结点，要安装docker（包括master和node共用的）
wget https://download.docker.com/linux/centos/7/x86_64/stable/Packages/docker-ce-18.06.0.ce-3.el7.x86_64.rpm yum install docker-ce-18.06.0.ce-3.el7.x86_64.rpm  设置主机名
 sh etc/set_hosts.sh
 安装etcd
 sh rpms/install_etcd.sh
 安装etcd证书
 sh keys/etcd/install_etc_key.sh
 修改etcd配置
 sh etc/set_etcd.sh
 启动etcd
 sh run/start_etcd.sh
 安装kube 程序
 sh rpms/install_kuber.sh
 安装kuber证书
 sh keys/k8s/install_k8s_key.sh
 修改kuber配置
 #设置master结点
sh etc/kube_cfg/set_kuber_cfg.sh
#设置node结点
sh etc/kube_cfg/set_kuber_node_cfg.sh
#如果master也作为node结点，则运行
sh etc/kube_cfg/set_kuber_master_node_cfg.sh
 启动kube
 sh run/start_kube.sh
#在任意一台master上执行： 开启认证
kubectl create clusterrolebinding kubelet-bootstrap &amp;ndash;clusterrole=system:node-bootstrapper &amp;ndash;user=kubelet-bootstrap</description>
    </item>
    
    <item>
      <title>区块链共识算法学习</title>
      <link>http://wonder.zxcsoft.com/post/qkl/qkl_sf/</link>
      <pubDate>Thu, 26 Apr 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/qkl/qkl_sf/</guid>
      <description> 等完善&amp;hellip; </description>
    </item>
    
    <item>
      <title>银行卡密钥相关</title>
      <link>http://wonder.zxcsoft.com/post/des/des_pin/</link>
      <pubDate>Thu, 26 Apr 2018 20:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/des/des_pin/</guid>
      <description>pin des PIN 明文：123456 磁卡上的PAN：1234 5678 9012 3456 78 截取下的PAN：6789 0123 4567 则用于PIN加密的PAN为：0x00 0x00 0x67 0x89 0x01 0x23 0x45 0x67 则PIN BLOCK为： 0x06 0x12 0x34 0x56 0xFF 0xFF 0xFF 0xFF 异或：0x00 0x00 0x67 0x89 0x01 0x23 0x45 0x67 结果为：0x06 0x12 0x53 0xDF 0xFE 0xDC 0xBA 0x98</description>
    </item>
    
    <item>
      <title>kuberadm start</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kubeadm_start/</link>
      <pubDate>Thu, 26 Apr 2018 10:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kubeadm_start/</guid>
      <description>kubernetes搭建比较复杂，所以选择先用kubeadm全自动来先试试手（奈何墙有点高，所以加了些插曲）
通过kubeadm安装 参考 官方文档
1. 准备环境 1.1 修改hostname  修改 /etc/hostname  1.2 关闭sellinux，关闭防火墙  setenforce 0 编辑/etc/selinux/config
 firewall-cmd &amp;ndash;state 查看状态
 systemctl stop firewalld.service # 停止firewall
 systemctl disable firewalld.service # 禁止firewall开机启动
  1.3 关闭swap swapoff -a 编辑 /etc/fstab 去掉swap配置（#号注释掉）  1.4 安装crictl (可选) go get github.com/kubernetes-incubator/cri-tools/cmd/crictl GOARCH=amd64 GOOS=linux go build  1.5 get docker image  运行kubeadm init 当提示请稍等后，检查/etc/kubernetes/manifests 目录下的yaml文件，里面会有需要的镜像和版本 通过hub.docker.com 中转，实现镜像的下载 具体方法请参考：kubeadm搭建（by mritd） 重新tag镜像(以下是我使用的，可直接pull后使用)</description>
    </item>
    
    <item>
      <title>kube问题汇总</title>
      <link>http://wonder.zxcsoft.com/post/kuber/kube_help/</link>
      <pubDate>Thu, 26 Apr 2018 10:46:49 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/kuber/kube_help/</guid>
      <description> 虚拟机建议用virutalbox
当时istio的bookinfo无法部署： reviews-v2-7bdf9b96b6-khg7s 老是会报错，提示无法创建目录，没权限，后来查是虚拟机sandbox版本太低，导致的一个bug，文件无法删除也无法修改
 virtualbox建议用nat 网络的方式，自己添加一个网卡，作为虚拟机集群的网络
然后每个主机在加一个hostonly的网卡，用于主机访问虚拟机
 硬盘没空间：
突然发现pod状态变成了：Evicted，还有挂起的，然后 通过 kubelet describe命令查看，发现是node空间满了，无法部署了：我看空间用了80%
 时间不同步：
时间不同步时，会出现 Unable to authenticate the request due to an error: x509: certificate has expired or is not yet valid 我同步机器时间后，问题解决。。。
 token不一致：
配置文件bootstrap.kubeconfig中token不一致，会导致这个错 failed to run Kubelet: cannot create certificate signing request: Unauthorized
  </description>
    </item>
    
    <item>
      <title>open source list</title>
      <link>http://wonder.zxcsoft.com/post/source_list/</link>
      <pubDate>Thu, 26 Apr 2018 10:38:52 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/source_list/</guid>
      <description> 开源项目整理  kubernetes istio knative  rss reader open source  miniflux https://github.com/miniflux/miniflux winds https://github.com/GetStream/Winds  系统监控  ansible http://www.ansible.com.cn/docs/intro_inventory.html  前端开发  flutter https://flutterchina.club/setup-macos/ angularjs angular dart https://webdev.dartlang.org/guides/get-started  网络协议  ipfs https://github.com/ipfs/ipfs  </description>
    </item>
    
    <item>
      <title>Learn markdown</title>
      <link>http://wonder.zxcsoft.com/post/learn-md/</link>
      <pubDate>Wed, 25 Apr 2018 12:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/learn-md/</guid>
      <description>标题  利用=（最高阶标题） 和 - （第二阶标题） 在行首插入1到6个#，对应标题1到6阶  区块使用  在每行前面，或者段落最前面加上&amp;gt; 表示区块引用,如：   aa
 aa dsafas
  列表  用星号、加号或减号来表示无序列表 用数字加英文句点（不在乎数字是几）表示有序列表，数字会重新自动生成  代码区块  缩进4个空格或者一个制表符，就是代码区块 如果段内有一小段代码，可以用`号包起来，如  printf();   如果代码中也有`号，可以用多个来标记开始和结束如：  printf(&amp;quot;`&amp;quot;);   引用一段代码, 如：引用部分c++代码  int a=1; int b=2; int c= a+b;  分隔线  在一行中用3个以上的星号、减号、底线来建立一个分隔线  链接  链接文字用[方括号]来标记，后面紧接着用圆括号闰插入网上链接 如：test link 链接标记： 两个方括号 test link 前一个是链接文字，后一个是标记，然后在后面标记这个id  强调  使用星号、底线 作为标志强调字词的符号 （用一个*或_包围的字词会转成EM标签，用两个会转成strong this is em this is strong  图片  添加图片 !</description>
    </item>
    
    <item>
      <title>grafana源码学习</title>
      <link>http://wonder.zxcsoft.com/post/grafana/grafana-src/</link>
      <pubDate>Wed, 25 Apr 2018 12:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/grafana/grafana-src/</guid>
      <description>grafana学习 1.整体流程了解 grafana-server(从main开始)  根据profile标志判断是否开启pprof 初始化版本、时间缀信息 初始化metrics包的版本信息
 在prometheus 中记录版本值1  创建grafanaServer
 init加载的清单
 api  通过registry.RegisterService注册http服务：HTTPServer  log  创建根root日志对象  login  在bus上注册句柄：&amp;rdquo;auth&amp;rdquo;, UpsertUser 扩展用户管理  setting
 记录系统标志（是否是windows）  extensions
 errors 引入github.com/pkg/errors包，在出错时，会记录栈信息，还有详细的函数信息  metrics
 初始化prometheus统计变量  plugins
 通过registry.RegisterService注册插件管理器：PluginManager  type Service interface { Init() error }  所有的插件都实现这个接口 在bus上注册句柄：&amp;rdquo;plugins&amp;rdquo;：ImportDashboard 在bus上注册事件监听：handlePluginStateChanged  services/alerting
 在bus上注册句柄：&amp;rdquo;alerting&amp;rdquo;, updateDashboardAlerts 在bus上注册句柄：&amp;rdquo;alerting&amp;rdquo;, validateDashboardAlerts 通过registry.RegisterService注册告警服务：AlertingService 在bus上注册句柄：&amp;rdquo;alerting&amp;rdquo;, handleNotificationTestCommand 在bus上注册句柄：&amp;rdquo;alerting&amp;rdquo;, handleAlertTestCommand  services/cleanup</description>
    </item>
    
    <item>
      <title>use hugo</title>
      <link>http://wonder.zxcsoft.com/post/hugo/use-hugo/</link>
      <pubDate>Wed, 25 Apr 2018 12:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/hugo/use-hugo/</guid>
      <description> hugo的安装 go get github.com/gohugoio/hugo  基本使用  创建一个网站项目 hugo new site hello 安装一个theme hugo将数据和展示分开了，显示部分由theme来管理 原理如下：  项目下的数据，会由hugo按格式读取，并约定好模板中的变更名，由theme来显示出来 比如：.Data表示content下的页面信息 theme就是go用来渲染的模板，而项目下content下的就是它的数据来源（默认用这个目录），也支持用其它目录   发布github  github上新创建一个repository 修改本地baseurl为github的：https://llhhbc.github.io/wonder/ 上传代码：  hugo ##生成静态文件 cd public git init git add . git commit -m &amp;quot;init&amp;quot; git remote add github https://github.com/llhhbc/wonder.git git push github master   在repository 的设置（setting）中，找到github pages 在source中选择分支，点击save（会自动刷新，然后会提示访问地址）  </description>
    </item>
    
    <item>
      <title>use hugo</title>
      <link>http://wonder.zxcsoft.com/post/use-hugo/</link>
      <pubDate>Wed, 25 Apr 2018 12:02:28 +0800</pubDate>
      
      <guid>http://wonder.zxcsoft.com/post/use-hugo/</guid>
      <description> hugo的安装 go get github.com/gohugoio/hugo  基本使用  创建一个网站项目 hugo new site hello 安装一个theme hugo将数据和展示分开了，显示部分由theme来管理 原理如下：  项目下的数据，会由hugo按格式读取，并约定好模板中的变更名，由theme来显示出来 比如：.Data表示content下的页面信息 theme就是go用来渲染的模板，而项目下content下的就是它的数据来源（默认用这个目录），也支持用其它目录   发布github  github上新创建一个repository 修改本地baseurl为github的：https://llhhbc.github.io/wonder/ 上传代码：  hugo ##生成静态文件 cd public git init git add . git commit -m &amp;quot;init&amp;quot; git remote add github https://github.com/llhhbc/wonder.git git push github master   在repository 的设置（setting）中，找到github pages 在source中选择分支，点击save（会自动刷新，然后会提示访问地址）  </description>
    </item>
    
  </channel>
</rss>